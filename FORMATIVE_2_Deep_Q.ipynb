{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadumbuya/Formative_2_Deep_Q_Learning/blob/main/FORMATIVE_2_Deep_Q.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install stable-baselines3[extra] gymnasium[atari] ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4grj9oz2zYf",
        "outputId": "37d9b54c-b27d-4f42-98ad-46f8fe7ed6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBZKXzvM0Ogd"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "import torch\n",
        "import os\n",
        "import ale_py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create logs directory\n",
        "log_dir = \"./logs/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Ensure Stable-Baselines3 uses GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train MLPPolicy model\n",
        "print(\"Training MLPPolicy Model...\")\n",
        "mlp_env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\")\n",
        "mlp_env = Monitor(mlp_env, log_dir)\n",
        "\n",
        "mlp_model = DQN(\"MlpPolicy\", mlp_env, verbose=1, learning_rate=1e-4, gamma=0.99, tensorboard_log=\"./mlp_dqn_tensorboard/\",device=device)\n",
        "mlp_model.learn(total_timesteps=200000)  # Train for 200k steps\n",
        "mlp_model.save(\"dqn_pong_mlp.zip\")\n",
        "mlp_env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Msa65f81phG",
        "outputId": "7977064a-1cc0-4976-d19b-e55e0a6980fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLPPolicy Model...\n",
            "Using cuda device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 201.62GB > 52.52GB\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./mlp_dqn_tensorboard/DQN_4\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 867      |\n",
            "|    ep_rew_mean      | -21      |\n",
            "|    exploration_rate | 0.835    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 355      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 3467     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0158   |\n",
            "|    n_updates        | 841      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 930      |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.647    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 361      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 7440     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.015    |\n",
            "|    n_updates        | 1834     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 943      |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.463    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 355      |\n",
            "|    time_elapsed     | 31       |\n",
            "|    total_timesteps  | 11313    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0156   |\n",
            "|    n_updates        | 2803     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 929      |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.294    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 347      |\n",
            "|    time_elapsed     | 42       |\n",
            "|    total_timesteps  | 14869    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00023  |\n",
            "|    n_updates        | 3692     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 909      |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.136    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 338      |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 18188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.032    |\n",
            "|    n_updates        | 4521     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 886      |\n",
            "|    ep_rew_mean      | -20.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 329      |\n",
            "|    time_elapsed     | 64       |\n",
            "|    total_timesteps  | 21272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000112 |\n",
            "|    n_updates        | 5292     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 873      |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 322      |\n",
            "|    time_elapsed     | 75       |\n",
            "|    total_timesteps  | 24448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000378 |\n",
            "|    n_updates        | 6086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 863      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 317      |\n",
            "|    time_elapsed     | 87       |\n",
            "|    total_timesteps  | 27602    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 6875     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 859      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 312      |\n",
            "|    time_elapsed     | 98       |\n",
            "|    total_timesteps  | 30916    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000125 |\n",
            "|    n_updates        | 7703     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 852      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 309      |\n",
            "|    time_elapsed     | 110      |\n",
            "|    total_timesteps  | 34085    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0415   |\n",
            "|    n_updates        | 8496     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 850      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 306      |\n",
            "|    time_elapsed     | 122      |\n",
            "|    total_timesteps  | 37399    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00751  |\n",
            "|    n_updates        | 9324     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 848      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 304      |\n",
            "|    time_elapsed     | 133      |\n",
            "|    total_timesteps  | 40699    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00636  |\n",
            "|    n_updates        | 10149    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 843      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 302      |\n",
            "|    time_elapsed     | 144      |\n",
            "|    total_timesteps  | 43817    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00188  |\n",
            "|    n_updates        | 10929    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 839      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 301      |\n",
            "|    time_elapsed     | 156      |\n",
            "|    total_timesteps  | 46993    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 11723    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 836      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 299      |\n",
            "|    time_elapsed     | 167      |\n",
            "|    total_timesteps  | 50184    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00789  |\n",
            "|    n_updates        | 12520    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 835      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 298      |\n",
            "|    time_elapsed     | 179      |\n",
            "|    total_timesteps  | 53448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000898 |\n",
            "|    n_updates        | 13336    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 831      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 297      |\n",
            "|    time_elapsed     | 189      |\n",
            "|    total_timesteps  | 56504    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 14100    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 831      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 297      |\n",
            "|    time_elapsed     | 201      |\n",
            "|    total_timesteps  | 59815    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00104  |\n",
            "|    n_updates        | 14928    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 829      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 296      |\n",
            "|    time_elapsed     | 212      |\n",
            "|    total_timesteps  | 62980    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000801 |\n",
            "|    n_updates        | 15719    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 828      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 295      |\n",
            "|    time_elapsed     | 223      |\n",
            "|    total_timesteps  | 66216    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0312   |\n",
            "|    n_updates        | 16528    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 827      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 295      |\n",
            "|    time_elapsed     | 235      |\n",
            "|    total_timesteps  | 69470    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00234  |\n",
            "|    n_updates        | 17342    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 827      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 294      |\n",
            "|    time_elapsed     | 246      |\n",
            "|    total_timesteps  | 72742    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000286 |\n",
            "|    n_updates        | 18160    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 826      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 294      |\n",
            "|    time_elapsed     | 258      |\n",
            "|    total_timesteps  | 75955    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000169 |\n",
            "|    n_updates        | 18963    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 825      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 269      |\n",
            "|    total_timesteps  | 79191    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00401  |\n",
            "|    n_updates        | 19772    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 824      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 280      |\n",
            "|    total_timesteps  | 82388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00283  |\n",
            "|    n_updates        | 20571    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 821      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 291      |\n",
            "|    total_timesteps  | 85593    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00889  |\n",
            "|    n_updates        | 21373    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 813      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 292      |\n",
            "|    time_elapsed     | 302      |\n",
            "|    total_timesteps  | 88727    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00515  |\n",
            "|    n_updates        | 22156    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 805      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 292      |\n",
            "|    time_elapsed     | 313      |\n",
            "|    total_timesteps  | 91862    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 22940    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 802      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 292      |\n",
            "|    time_elapsed     | 325      |\n",
            "|    total_timesteps  | 95052    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00483  |\n",
            "|    n_updates        | 23737    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 801      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 292      |\n",
            "|    time_elapsed     | 336      |\n",
            "|    total_timesteps  | 98298    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00719  |\n",
            "|    n_updates        | 24549    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 803      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 292      |\n",
            "|    time_elapsed     | 347      |\n",
            "|    total_timesteps  | 101570   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0189   |\n",
            "|    n_updates        | 25367    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 805      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 359      |\n",
            "|    total_timesteps  | 104983   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.012    |\n",
            "|    n_updates        | 26220    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 809      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 371      |\n",
            "|    total_timesteps  | 108511   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0345   |\n",
            "|    n_updates        | 27102    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 808      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 111692   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00732  |\n",
            "|    n_updates        | 27897    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 809      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 394      |\n",
            "|    total_timesteps  | 115024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0293   |\n",
            "|    n_updates        | 28730    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 808      |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 118214   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00971  |\n",
            "|    n_updates        | 29528    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 808      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 291      |\n",
            "|    time_elapsed     | 417      |\n",
            "|    total_timesteps  | 121514   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00317  |\n",
            "|    n_updates        | 30353    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 812      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 429      |\n",
            "|    total_timesteps  | 125024   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0042   |\n",
            "|    n_updates        | 31230    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 815      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 441      |\n",
            "|    total_timesteps  | 128457   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00764  |\n",
            "|    n_updates        | 32089    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 816      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 453      |\n",
            "|    total_timesteps  | 131756   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0218   |\n",
            "|    n_updates        | 32913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 815      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 464      |\n",
            "|    total_timesteps  | 134966   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00792  |\n",
            "|    n_updates        | 33716    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 820      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 476      |\n",
            "|    total_timesteps  | 138510   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0215   |\n",
            "|    n_updates        | 34602    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 818      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 487      |\n",
            "|    total_timesteps  | 141641   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00381  |\n",
            "|    n_updates        | 35385    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 819      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 498      |\n",
            "|    total_timesteps  | 144855   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00172  |\n",
            "|    n_updates        | 36188    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 819      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 510      |\n",
            "|    total_timesteps  | 148133   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00311  |\n",
            "|    n_updates        | 37008    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 818      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 521      |\n",
            "|    total_timesteps  | 151287   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00478  |\n",
            "|    n_updates        | 37796    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 817      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 532      |\n",
            "|    total_timesteps  | 154472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0285   |\n",
            "|    n_updates        | 38592    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 818      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 543      |\n",
            "|    total_timesteps  | 157745   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00459  |\n",
            "|    n_updates        | 39411    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 817      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 554      |\n",
            "|    total_timesteps  | 160863   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000604 |\n",
            "|    n_updates        | 40190    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 817      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 565      |\n",
            "|    total_timesteps  | 164113   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0872   |\n",
            "|    n_updates        | 41003    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 820      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 577      |\n",
            "|    total_timesteps  | 167546   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0728   |\n",
            "|    n_updates        | 41861    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 821      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 290      |\n",
            "|    time_elapsed     | 588      |\n",
            "|    total_timesteps  | 170810   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0307   |\n",
            "|    n_updates        | 42677    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 824      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 600      |\n",
            "|    total_timesteps  | 174263   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 43540    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 824      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 612      |\n",
            "|    total_timesteps  | 177460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000199 |\n",
            "|    n_updates        | 44339    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 826      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 624      |\n",
            "|    total_timesteps  | 180852   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000116 |\n",
            "|    n_updates        | 45187    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 825      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 635      |\n",
            "|    total_timesteps  | 184074   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0302   |\n",
            "|    n_updates        | 45993    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 824      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 647      |\n",
            "|    total_timesteps  | 187395   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000479 |\n",
            "|    n_updates        | 46823    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 822      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 658      |\n",
            "|    total_timesteps  | 190701   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0144   |\n",
            "|    n_updates        | 47650    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 822      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 669      |\n",
            "|    total_timesteps  | 193891   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000317 |\n",
            "|    n_updates        | 48447    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 820      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 289      |\n",
            "|    time_elapsed     | 680      |\n",
            "|    total_timesteps  | 197065   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0163   |\n",
            "|    n_updates        | 49241    |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CnnPolicy model\n",
        "print(\"Training CnnPolicy Model...\")\n",
        "cnn_env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\")\n",
        "cnn_env = Monitor(cnn_env, log_dir)\n",
        "\n",
        "cnn_model = DQN(\"CnnPolicy\", cnn_env, verbose=1, buffer_size=1000000, learning_starts=10000, batch_size=16, gamma=0.99,\n",
        "                learning_rate=1e-4, target_update_interval=1000, train_freq=(4, \"step\"), exploration_fraction=0.1,\n",
        "                exploration_final_eps=0.01, tensorboard_log=\"./cnn_dqn_tensorboard/\",device=device)"
      ],
      "metadata": {
        "id": "gdE9nMyR2DYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2265c583-3475-4793-f558-99c3ed2104cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CnnPolicy Model...\n",
            "Using cuda device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 201.62GB > 11.43GB\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create checkpoint callback to save the CNN model periodically\n",
        "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=log_dir, name_prefix=\"dqn_checkpoint\")\n",
        "\n",
        "cnn_model.learn(total_timesteps=50000, log_interval=10, callback=checkpoint_callback)\n",
        "cnn_model.save(\"dqn_model.zip\")\n",
        "cnn_env.close()"
      ],
      "metadata": {
        "id": "q9Ef0eoL2US-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae2c658-4d5b-418b-d396-62e6ffd67872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./cnn_dqn_tensorboard/DQN_4\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 900      |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 10       |\n",
            "|    fps              | 1048     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 8999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 846      |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 414      |\n",
            "|    time_elapsed     | 40       |\n",
            "|    total_timesteps  | 16914    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000222 |\n",
            "|    n_updates        | 1728     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 822      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 30       |\n",
            "|    fps              | 328      |\n",
            "|    time_elapsed     | 75       |\n",
            "|    total_timesteps  | 24662    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000719 |\n",
            "|    n_updates        | 3665     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 835      |\n",
            "|    ep_rew_mean      | -20.8    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 293      |\n",
            "|    time_elapsed     | 113      |\n",
            "|    total_timesteps  | 33413    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.026    |\n",
            "|    n_updates        | 5853     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 841      |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 50       |\n",
            "|    fps              | 275      |\n",
            "|    time_elapsed     | 152      |\n",
            "|    total_timesteps  | 42065    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00163  |\n",
            "|    n_updates        | 8016     |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CNN model\n",
        "eval_env = gym.make(\"ALE/Pong-v5\", render_mode=\"rgb_array\")\n",
        "eval_env = Monitor(eval_env, log_dir)\n",
        "mean_reward_cnn, std_reward_cnn = evaluate_policy(cnn_model, eval_env, n_eval_episodes=10)\n",
        "print(f\"CnnPolicy - Mean Reward: {mean_reward_cnn}  {std_reward_cnn}\")\n",
        "eval_env.close()"
      ],
      "metadata": {
        "id": "UE6fCFqg2ZHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f130356e-4c0e-4f45-8992-5016a5bbf53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CnnPolicy - Mean Reward: -21.0  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Tain with hyper parameters"
      ],
      "metadata": {
        "id": "0amh3i7R-IUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Train a DQN agent on Atari Breakout with hyperparameter support.\"\"\"\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Train a DQN agent for Atari Breakout using keras-rl\")\n",
        "    parser.add_argument(\"--env\", type=str, default=\"Breakout-v0\", help=\"Gym environment name\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"Learning rate for the optimizer\")\n",
        "    parser.add_argument(\"--nb_steps\", type=int, default=50000, help=\"Number of training steps\")\n",
        "    parser.add_argument(\"--nb_steps_warmup\", type=int, default=1000, help=\"Warmup steps before training begins\")\n",
        "    parser.add_argument(\"--target_model_update\", type=float, default=1e-2, help=\"Frequency of target model updates\")\n",
        "    parser.add_argument(\"--memory_limit\", type=int, default=50000, help=\"Limit for SequentialMemory\")\n",
        "    parser.add_argument(\"--window_length\", type=int, default=1, help=\"Window length for the memory\")\n",
        "    parser.add_argument(\"--eps\", type=float, default=1.0, help=\"Initial epsilon for exploration\")\n",
        "    parser.add_argument(\"--save_file\", type=str, default=\"policy.h5\", help=\"Filename to save the trained model weights\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "def build_model(input_shape, nb_actions, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(1,) + input_shape))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(nb_actions, activation='linear'))\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # Create the gym environment based on the parameter\n",
        "    env = gym.make(args.env)\n",
        "    nb_actions = env.action_space.n\n",
        "\n",
        "    # Build the model using the specified hyperparameters\n",
        "    model = build_model(env.observation_space.shape, nb_actions, args.learning_rate)\n",
        "\n",
        "    # Setup memory and policy using command-line parameters\n",
        "    memory = SequentialMemory(limit=args.memory_limit, window_length=args.window_length)\n",
        "    policy = EpsGreedyQPolicy(eps=args.eps)\n",
        "\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                   nb_actions=nb_actions,\n",
        "                   nb_steps_warmup=args.nb_steps_warmup,\n",
        "                   target_model_update=args.target_model_update)\n",
        "\n",
        "    dqn.compile(Adam(lr=args.learning_rate), metrics=['mae'])\n",
        "    dqn.fit(env, nb_steps=args.nb_steps, visualize=False, verbose=2)\n",
        "\n",
        "    dqn.save_weights(args.save_file, overwrite=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "dScaC3wP9m7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with hyper parameters"
      ],
      "metadata": {
        "id": "lME64RSn-umZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Play Breakout with a trained DQN agent using GreedyQPolicy.\"\"\"\n",
        "\n",
        "import argparse\n",
        "import gym\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import GreedyQPolicy\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"Play Breakout with a trained DQN agent\")\n",
        "    parser.add_argument(\"--env\", type=str, default=\"Breakout-v0\", help=\"Gym environment name\")\n",
        "    parser.add_argument(\"--model_file\", type=str, default=\"policy.h5\", help=\"File with trained model weights\")\n",
        "    parser.add_argument(\"--episodes\", type=int, default=5, help=\"Number of episodes to play\")\n",
        "    parser.add_argument(\"--memory_limit\", type=int, default=50000, help=\"Memory limit for the agent\")\n",
        "    parser.add_argument(\"--window_length\", type=int, default=1, help=\"Window length for the memory\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "def build_model(input_shape, nb_actions):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(1,) + input_shape))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(nb_actions, activation='linear'))\n",
        "    return model\n",
        "\n",
        "def build_agent(model, nb_actions, memory_limit, window_length):\n",
        "    memory = SequentialMemory(limit=memory_limit, window_length=window_length)\n",
        "    policy = GreedyQPolicy()\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=nb_actions)\n",
        "    return dqn\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # Create the gym environment\n",
        "    env = gym.make(args.env)\n",
        "    nb_actions = env.action_space.n\n",
        "\n",
        "    # Build model and agent matching the training architecture\n",
        "    model = build_model(env.observation_space.shape, nb_actions)\n",
        "    dqn = build_agent(model, nb_actions, args.memory_limit, args.window_length)\n",
        "\n",
        "    # Load the trained weights\n",
        "    dqn.load_weights(args.model_file)\n",
        "\n",
        "    # Run episodes\n",
        "    for episode in range(args.episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = dqn.forward(state)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
        "    env.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UW9xDhnR-xIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}